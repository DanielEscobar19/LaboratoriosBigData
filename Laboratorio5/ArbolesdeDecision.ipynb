{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["#Árboles de Decisión"],"metadata":{"id":"tQC9ULK3zzeD"}},{"cell_type":"markdown","source":["##Descripción de los Árboles de Decisión\n","La inducción de árboles de decisión es un proceso utilizado en la minería de datos para construir modelos predictivos y tomar decisiones basadas en características del conjunto de datos. Un árbol de decisión es una estructura en forma de árbol compuesta por nodos y ramas que representan decisiones y resultados. Cada nodo interno del árbol representa una característica del conjunto de datos, y las ramas que salen de ese nodo representan los posibles valores que puede tomar esa característica. Los nodos hoja representan los resultados o predicciones finales.\n","\n","El proceso de inducción de árboles de decisión generalmente se realiza utilizando un algoritmo como el algoritmo ID3 (Iterative Dichotomiser 3), el algoritmo C4.5 o el algoritmo CART (Classification and Regression Trees). Estos algoritmos buscan encontrar la mejor característica para dividir el conjunto de datos en cada paso y construir el árbol de decisión de manera iterativa.\n","\n","El algoritmo selecciona la característica que proporciona la mayor ganancia de información o la mayor reducción de la impureza en el conjunto de datos. La ganancia de información se refiere a la medida de cuánta información se obtiene al dividir el conjunto de datos utilizando una característica en particular. La impureza se refiere a la medida de qué tan mezcladas están las clases en el conjunto de datos.\n","\n","Durante la construcción del árbol, el algoritmo puede detenerse en diferentes condiciones, como cuando todas las muestras pertenecen a la misma clase, cuando no hay más características disponibles o cuando se alcanza un límite de profundidad predefinido.\n","\n","Una vez que se ha construido el árbol de decisión, se puede utilizar para realizar predicciones en nuevas instancias o para tomar decisiones basadas en las características proporcionadas. Cada instancia sigue el camino desde la raíz hasta un nodo hoja basado en los valores de sus características, y la clase asociada con ese nodo hoja se considera la predicción o decisión final.\n","\n","Los árboles de decisión son atractivos porque son fácilmente interpretables y permiten visualizar las reglas de decisión. Sin embargo, también pueden ser propensos al sobreajuste y pueden requerir técnicas de poda o regularización para mejorar su rendimiento en datos no vistos."],"metadata":{"id":"A9YS4__lzHxl"}},{"cell_type":"markdown","source":["##¿Cuándo utilizar los árboles de decisión en la minería de datos?\n","\n","Los árboles de decisión son algoritmos versátiles que pueden funcionar bien en una variedad de conjuntos de datos en minería de datos. Sin embargo, algunos tipos de conjuntos de datos son especialmente adecuados para trabajar con árboles de decisión. Aquí hay algunos ejemplos:\n","\n","1. Conjuntos de datos con características categóricas y numéricas: Los árboles de decisión pueden manejar tanto características categóricas como numéricas sin requerir transformaciones adicionales. Por lo tanto, son útiles cuando se trabaja con conjuntos de datos que contienen una combinación de ambos tipos de características.\n","\n","2. Conjuntos de datos con características de alta dimensionalidad: Los árboles de decisión pueden manejar conjuntos de datos con muchas características de manera eficiente. A diferencia de algunos algoritmos que pueden verse afectados por la dimensionalidad alta, los árboles de decisión pueden lidiar con esta situación y seleccionar automáticamente las características más importantes para la clasificación o regresión.\n","\n","3. Conjuntos de datos con relaciones no lineales: Los árboles de decisión son capaces de capturar relaciones no lineales entre características y etiquetas. Pueden formar divisiones y combinaciones no lineales en el espacio de características, lo que los hace adecuados para conjuntos de datos donde las relaciones no son lineales.\n","\n","4. Conjuntos de datos con características faltantes o valores atípicos: Los árboles de decisión pueden manejar fácilmente características faltantes o valores atípicos sin requerir imputación de datos o preprocesamiento adicional. Esto los convierte en una buena opción cuando se trabaja con conjuntos de datos que pueden contener valores faltantes o atípicos.\n","\n","5. Conjuntos de datos interpretables: Los árboles de decisión tienen la ventaja de ser modelos interpretables. Puedes comprender y visualizar fácilmente las reglas de decisión en forma de un árbol, lo que ayuda a comprender cómo se toman las decisiones basadas en las características del conjunto de datos.\n","\n","Sin embargo, vale la pena recordar que los árboles de decisión también tienen limitaciones. Pueden ser propensos al sobreajuste en conjuntos de datos ruidosos o con muchos datos irrelevantes. En tales casos, pueden ser necesarios enfoques de mejora, como la poda del árbol o el uso de ensamblajes de árboles, como Random Forest o Gradient Boosting."],"metadata":{"id":"nxKq6zxAz2oC"}},{"cell_type":"markdown","source":["##Construcción de un Árbol de Decisión\n","\n","Para programar la construcción de un árbol de decisión para minería de datos en Python, pueden utilizar bibliotecas populares como scikit-learn. A continuación, un ejemplo básico de cómo programar un árbol de decisión utilizando scikit-learn:\n","\n","1. Instalar scikit-learn:\n","Asegúrense de tener scikit-learn instalado en tu entorno Python. Pueden instalarlo utilizando el siguiente comando en tu terminal o consola:\n","\n","```\n","pip install scikit-learn\n","```\n","(Solo necesario en caso de trabajar externo a Google Colaboratory)\n","\n","2. Importar las bibliotecas necesarias: Importen las bibliotecas necesarias, incluyendo las clases DecisionTreeClassifier y train_test_split de scikit-learn, así como cualquier otra biblioteca adicional que necesiten:"],"metadata":{"id":"M17UnNAP1RaY"}},{"cell_type":"code","source":["from sklearn.tree import DecisionTreeClassifier\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score\n","from sklearn.datasets import load_iris\n","import pandas as pd"],"metadata":{"id":"W6DIP6QI11mm","executionInfo":{"status":"ok","timestamp":1685788231900,"user_tz":360,"elapsed":232,"user":{"displayName":"Totis","userId":"06866148035047094242"}}},"execution_count":39,"outputs":[]},{"cell_type":"markdown","source":["3. Preparar los datos: Prepara tus datos de entrenamiento y prueba. Asegúranse de tener características (features) y etiquetas (labels) adecuadas para el entrenamiento y la evaluación del modelo. Puedes usar bibliotecas como pandas para cargar y procesar tus datos:"],"metadata":{"id":"O8g4MoGg13mr"}},{"cell_type":"code","source":["# En caso de datasets a cargar desde un archivo CSV\n","# data = pd.read_csv('datos.csv')\n","\n","# Cargar el conjunto de datos de flores Iris\n","# Separar características y etiquetas\n","data = load_iris()\n","X = data.data  # Características\n","y = data.target  # Etiquetas"],"metadata":{"id":"T9LQuNcp16_b","executionInfo":{"status":"ok","timestamp":1685788232133,"user_tz":360,"elapsed":234,"user":{"displayName":"Totis","userId":"06866148035047094242"}}},"execution_count":40,"outputs":[]},{"cell_type":"markdown","source":["4. Dividir los datos en conjuntos de entrenamiento y prueba: Dividan los datos en conjuntos de entrenamiento y prueba para evaluar el rendimiento del modelo. Usaremos la función train_test_split de scikit-learn:"],"metadata":{"id":"29HviPiq2UnR"}},{"cell_type":"code","source":["X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"],"metadata":{"id":"9ysIjQuh2YP1","executionInfo":{"status":"ok","timestamp":1685788232133,"user_tz":360,"elapsed":11,"user":{"displayName":"Totis","userId":"06866148035047094242"}}},"execution_count":41,"outputs":[]},{"cell_type":"markdown","source":["5. Crear y entrenar el modelo del árbol de decisión: Creen una instancia del clasificador DecisionTreeClassifier y luego entrenen el modelo utilizando los datos de entrenamiento:"],"metadata":{"id":"tWF4p1zC2d7d"}},{"cell_type":"code","source":["# Crear instancia del árbol de decisión\n","clf = DecisionTreeClassifier()\n","\n","# Entrenar el modelo\n","clf.fit(X_train, y_train)"],"metadata":{"id":"nhxtV3Xf2fyE","colab":{"base_uri":"https://localhost:8080/","height":75},"executionInfo":{"status":"ok","timestamp":1685788232133,"user_tz":360,"elapsed":11,"user":{"displayName":"Totis","userId":"06866148035047094242"}},"outputId":"9b41a230-c67f-4245-b9f6-e2b7ea2fe39e"},"execution_count":42,"outputs":[{"output_type":"execute_result","data":{"text/plain":["DecisionTreeClassifier()"],"text/html":["<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div></div></div>"]},"metadata":{},"execution_count":42}]},{"cell_type":"markdown","source":["6. Realizar predicciones:\n","Utilizen el modelo entrenado para hacer predicciones en nuevos datos:"],"metadata":{"id":"VJK3JVIm2lSG"}},{"cell_type":"code","source":["# Realizar predicciones en los datos de prueba\n","y_pred = clf.predict(X_test)"],"metadata":{"id":"TBMR2JLd2n5Z","executionInfo":{"status":"ok","timestamp":1685788232134,"user_tz":360,"elapsed":10,"user":{"displayName":"Totis","userId":"06866148035047094242"}}},"execution_count":43,"outputs":[]},{"cell_type":"markdown","source":["7. Evaluar el modelo: Evalúen el rendimiento del modelo utilizando métricas como precisión, recall, puntaje F1 o cualquier otra métrica relevante para el problema:"],"metadata":{"id":"toENtHE32q3M"}},{"cell_type":"code","source":["# Calcular precisión del modelo\n","accuracy = accuracy_score(y_test, y_pred)\n","print(\"Precisión del modelo:\", accuracy)"],"metadata":{"id":"cjKGVMXp2s-O","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1685788232134,"user_tz":360,"elapsed":10,"user":{"displayName":"Totis","userId":"06866148035047094242"}},"outputId":"67b6fb1a-61cb-44bd-f9b0-79ae48f64ce3"},"execution_count":44,"outputs":[{"output_type":"stream","name":"stdout","text":["Precisión del modelo: 1.0\n"]}]},{"cell_type":"markdown","source":["Este es un ejemplo básico de cómo programar un árbol de decisión en Python utilizando scikit-learn. Pueden personalizarlo según sus necesidades específicas, como ajustar los hiperparámetros del árbol de decisión o utilizar diferentes métricas de evaluación.\n","\n","### Ejemplo Básico Completo\n","\n","Supongamos que tienes un conjunto de datos de flores con características como longitud y ancho del sépalo y pétalo, y la etiqueta de la especie de la flor (por ejemplo, setosa, versicolor o virginica). Queremos construir un modelo de árbol de decisión para clasificar las flores en base a estas características."],"metadata":{"id":"QHaMFyDP20DA"}},{"cell_type":"code","source":["from sklearn.datasets import load_iris\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score, classification_report\n","\n","# Cargar el conjunto de datos de flores Iris\n","data = load_iris()\n","X = data.data  # Características\n","y = data.target  # Etiquetas\n","\n","# Dividir los datos en conjuntos de entrenamiento y prueba\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Crear una instancia del clasificador de árbol de decisión\n","clf = DecisionTreeClassifier()\n","\n","# Entrenar el modelo\n","clf.fit(X_train, y_train)\n","\n","# Realizar predicciones en los datos de prueba\n","y_pred = clf.predict(X_test)\n","\n","# Calcular la precisión del modelo\n","accuracy = accuracy_score(y_test, y_pred)\n","print(\"Precisión del modelo:\", accuracy)\n","\n","# Imprimir el reporte de clasificación\n","target_names = data.target_names\n","print(classification_report(y_test, y_pred, target_names=target_names))"],"metadata":{"id":"fZdtZNG83D_J","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1685788232134,"user_tz":360,"elapsed":8,"user":{"displayName":"Totis","userId":"06866148035047094242"}},"outputId":"10ff967c-f24e-4645-aebb-b64a49005548"},"execution_count":45,"outputs":[{"output_type":"stream","name":"stdout","text":["Precisión del modelo: 1.0\n","              precision    recall  f1-score   support\n","\n","      setosa       1.00      1.00      1.00        10\n","  versicolor       1.00      1.00      1.00         9\n","   virginica       1.00      1.00      1.00        11\n","\n","    accuracy                           1.00        30\n","   macro avg       1.00      1.00      1.00        30\n","weighted avg       1.00      1.00      1.00        30\n","\n"]}]},{"cell_type":"markdown","source":["En este ejemplo, utilizamos el conjunto de datos de flores Iris de scikit-learn. Cargamos las características en `X` y las etiquetas en `y`. Luego, dividimos los datos en conjuntos de entrenamiento y prueba utilizando la función `train_test_split`.\n","\n","Creamos una instancia del clasificador `DecisionTreeClassifier` y lo entrenamos utilizando los datos de entrenamiento. A continuación, realizamos predicciones en los datos de prueba utilizando el método `predict` del clasificador entrenado.\n","\n","Calculamos la precisión del modelo comparando las etiquetas reales (`y_test`) con las etiquetas predichas (`y_pred`) utilizando la métrica `accuracy_score`. Luego imprimimos la precisión del modelo.\n","\n","Además, utilizamos la función `classification_report` de scikit-learn para obtener un reporte detallado de la clasificación, que incluye precisiones, exhaustividades, puntajes F1 y soporte para cada clase. Imprimimos este reporte utilizando los nombres de las clases del conjunto de datos.\n","\n","Esto dará una idea más completa de cómo se desempeña el modelo en cada clase y qué métricas son relevantes en la evaluación.\n","\n","Recuerden que este ejemplo utiliza el conjunto de datos Iris para ilustrar el uso del algoritmo de árbol de decisión. Pueden aplicar un enfoque similar utilizando otros conjuntos de datos y adaptarlo."],"metadata":{"id":"jjc-uazv3XSh"}},{"cell_type":"markdown","source":["##Graficar el Árbol de Decisión\n","\n","Para imprimir el árbol de decisión final creado para un dataset en Python, pueden utilizar la función `export_graphviz` de scikit-learn junto con la biblioteca `graphviz` para generar una representación visual del árbol. Aquí tienen un ejemplo de cómo hacerlo:\n","\n","1. Instalar la biblioteca graphviz si aún no la tienen instalada. Pueden instalarla utilizando pip (De nuevo, solamente fuera de Colaboratory):\n","\n","```\n","pip install graphviz\n","```\n","\n","2. Importar las bibliotecas necesarias:"],"metadata":{"id":"JojPdUqA30tr"}},{"cell_type":"code","source":["from sklearn.datasets import load_iris\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.tree import export_graphviz\n","from sklearn.datasets import load_iris\n","import graphviz"],"metadata":{"id":"taBpo91A4Q6v","executionInfo":{"status":"ok","timestamp":1685788232134,"user_tz":360,"elapsed":7,"user":{"displayName":"Totis","userId":"06866148035047094242"}}},"execution_count":46,"outputs":[]},{"cell_type":"markdown","source":["3. Carga tu conjunto de datos. En este ejemplo, utilizaremos el conjunto de datos de flores Iris:"],"metadata":{"id":"T2yaw_TO4THB"}},{"cell_type":"code","source":["data = load_iris()\n","X = data.data\n","y = data.target"],"metadata":{"id":"xhucKaFy4VtE","executionInfo":{"status":"ok","timestamp":1685788232134,"user_tz":360,"elapsed":7,"user":{"displayName":"Totis","userId":"06866148035047094242"}}},"execution_count":47,"outputs":[]},{"cell_type":"markdown","source":["4. Crea una instancia del clasificador de árbol de decisión y ajústenlo a sus datos:"],"metadata":{"id":"eSzbHKIf4X4S"}},{"cell_type":"code","source":["clf = DecisionTreeClassifier()\n","clf.fit(X, y)"],"metadata":{"id":"uPMpszi94ZVO","colab":{"base_uri":"https://localhost:8080/","height":75},"executionInfo":{"status":"ok","timestamp":1685788232134,"user_tz":360,"elapsed":7,"user":{"displayName":"Totis","userId":"06866148035047094242"}},"outputId":"b32d4a0a-2314-4e83-f8c8-b69a112edd4d"},"execution_count":48,"outputs":[{"output_type":"execute_result","data":{"text/plain":["DecisionTreeClassifier()"],"text/html":["<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div></div></div>"]},"metadata":{},"execution_count":48}]},{"cell_type":"markdown","source":["5. Generar una representación gráfica del árbol de decisión utilizando `export_graphviz` y `graphviz`:"],"metadata":{"id":"O2SA3tpj4ceY"}},{"cell_type":"code","source":["dot_data = export_graphviz(clf, out_file=None,\n","                           feature_names=data.feature_names,\n","                           class_names=data.target_names,\n","                           filled=True, rounded=True,\n","                           special_characters=True)\n","\n","graph = graphviz.Source(dot_data)\n","graph.render(\"arbol_decision\")  # Guarda el árbol en un archivo en formato PDF\n","\n","# También puedes mostrar el árbol directamente en el notebook\n","graph"],"metadata":{"id":"XIWvWGXZ4hB2","colab":{"base_uri":"https://localhost:8080/","height":916},"executionInfo":{"status":"ok","timestamp":1685788232135,"user_tz":360,"elapsed":7,"user":{"displayName":"Totis","userId":"06866148035047094242"}},"outputId":"d7b32ff1-d924-46a3-f4d6-828a4b813b9d"},"execution_count":49,"outputs":[{"output_type":"execute_result","data":{"image/svg+xml":"<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.43.0 (0)\n -->\n<!-- Title: Tree Pages: 1 -->\n<svg width=\"852pt\" height=\"671pt\"\n viewBox=\"0.00 0.00 852.00 671.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 667)\">\n<title>Tree</title>\n<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-667 848,-667 848,4 -4,4\"/>\n<!-- 0 -->\n<g id=\"node1\" class=\"node\">\n<title>0</title>\n<path fill=\"#ffffff\" stroke=\"black\" d=\"M507.5,-663C507.5,-663 385.5,-663 385.5,-663 379.5,-663 373.5,-657 373.5,-651 373.5,-651 373.5,-592 373.5,-592 373.5,-586 379.5,-580 385.5,-580 385.5,-580 507.5,-580 507.5,-580 513.5,-580 519.5,-586 519.5,-592 519.5,-592 519.5,-651 519.5,-651 519.5,-657 513.5,-663 507.5,-663\"/>\n<text text-anchor=\"start\" x=\"381.5\" y=\"-647.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">petal width (cm) ≤ 0.8</text>\n<text text-anchor=\"start\" x=\"411\" y=\"-632.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.667</text>\n<text text-anchor=\"start\" x=\"401.5\" y=\"-617.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 150</text>\n<text text-anchor=\"start\" x=\"388.5\" y=\"-602.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [50, 50, 50]</text>\n<text text-anchor=\"start\" x=\"403\" y=\"-587.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = setosa</text>\n</g>\n<!-- 1 -->\n<g id=\"node2\" class=\"node\">\n<title>1</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M416,-536.5C416,-536.5 323,-536.5 323,-536.5 317,-536.5 311,-530.5 311,-524.5 311,-524.5 311,-480.5 311,-480.5 311,-474.5 317,-468.5 323,-468.5 323,-468.5 416,-468.5 416,-468.5 422,-468.5 428,-474.5 428,-480.5 428,-480.5 428,-524.5 428,-524.5 428,-530.5 422,-536.5 416,-536.5\"/>\n<text text-anchor=\"start\" x=\"341.5\" y=\"-521.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"328.5\" y=\"-506.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 50</text>\n<text text-anchor=\"start\" x=\"319\" y=\"-491.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [50, 0, 0]</text>\n<text text-anchor=\"start\" x=\"326\" y=\"-476.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = setosa</text>\n</g>\n<!-- 0&#45;&gt;1 -->\n<g id=\"edge1\" class=\"edge\">\n<title>0&#45;&gt;1</title>\n<path fill=\"none\" stroke=\"black\" d=\"M419.79,-579.91C412.38,-568.65 404.33,-556.42 396.88,-545.11\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"399.75,-543.1 391.33,-536.67 393.9,-546.94 399.75,-543.1\"/>\n<text text-anchor=\"middle\" x=\"386.28\" y=\"-557.45\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">True</text>\n</g>\n<!-- 2 -->\n<g id=\"node3\" class=\"node\">\n<title>2</title>\n<path fill=\"#ffffff\" stroke=\"black\" d=\"M588.5,-544C588.5,-544 458.5,-544 458.5,-544 452.5,-544 446.5,-538 446.5,-532 446.5,-532 446.5,-473 446.5,-473 446.5,-467 452.5,-461 458.5,-461 458.5,-461 588.5,-461 588.5,-461 594.5,-461 600.5,-467 600.5,-473 600.5,-473 600.5,-532 600.5,-532 600.5,-538 594.5,-544 588.5,-544\"/>\n<text text-anchor=\"start\" x=\"454.5\" y=\"-528.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">petal width (cm) ≤ 1.75</text>\n<text text-anchor=\"start\" x=\"495.5\" y=\"-513.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.5</text>\n<text text-anchor=\"start\" x=\"478.5\" y=\"-498.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 100</text>\n<text text-anchor=\"start\" x=\"469\" y=\"-483.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 50, 50]</text>\n<text text-anchor=\"start\" x=\"471\" y=\"-468.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = versicolor</text>\n</g>\n<!-- 0&#45;&gt;2 -->\n<g id=\"edge2\" class=\"edge\">\n<title>0&#45;&gt;2</title>\n<path fill=\"none\" stroke=\"black\" d=\"M473.21,-579.91C479.01,-571.1 485.2,-561.7 491.18,-552.61\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"494.26,-554.3 496.83,-544.02 488.41,-550.45 494.26,-554.3\"/>\n<text text-anchor=\"middle\" x=\"501.88\" y=\"-564.81\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">False</text>\n</g>\n<!-- 3 -->\n<g id=\"node4\" class=\"node\">\n<title>3</title>\n<path fill=\"#4de88e\" stroke=\"black\" d=\"M480,-425C480,-425 345,-425 345,-425 339,-425 333,-419 333,-413 333,-413 333,-354 333,-354 333,-348 339,-342 345,-342 345,-342 480,-342 480,-342 486,-342 492,-348 492,-354 492,-354 492,-413 492,-413 492,-419 486,-425 480,-425\"/>\n<text text-anchor=\"start\" x=\"341\" y=\"-409.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">petal length (cm) ≤ 4.95</text>\n<text text-anchor=\"start\" x=\"377\" y=\"-394.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.168</text>\n<text text-anchor=\"start\" x=\"371.5\" y=\"-379.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 54</text>\n<text text-anchor=\"start\" x=\"362\" y=\"-364.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 49, 5]</text>\n<text text-anchor=\"start\" x=\"360\" y=\"-349.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = versicolor</text>\n</g>\n<!-- 2&#45;&gt;3 -->\n<g id=\"edge3\" class=\"edge\">\n<title>2&#45;&gt;3</title>\n<path fill=\"none\" stroke=\"black\" d=\"M484.99,-460.91C476.29,-451.74 466.98,-441.93 458.03,-432.49\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"460.36,-429.87 450.94,-425.02 455.29,-434.68 460.36,-429.87\"/>\n</g>\n<!-- 12 -->\n<g id=\"node13\" class=\"node\">\n<title>12</title>\n<path fill=\"#843de6\" stroke=\"black\" d=\"M702,-425C702,-425 567,-425 567,-425 561,-425 555,-419 555,-413 555,-413 555,-354 555,-354 555,-348 561,-342 567,-342 567,-342 702,-342 702,-342 708,-342 714,-348 714,-354 714,-354 714,-413 714,-413 714,-419 708,-425 702,-425\"/>\n<text text-anchor=\"start\" x=\"563\" y=\"-409.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">petal length (cm) ≤ 4.85</text>\n<text text-anchor=\"start\" x=\"599\" y=\"-394.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.043</text>\n<text text-anchor=\"start\" x=\"593.5\" y=\"-379.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 46</text>\n<text text-anchor=\"start\" x=\"584\" y=\"-364.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 1, 45]</text>\n<text text-anchor=\"start\" x=\"586\" y=\"-349.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = virginica</text>\n</g>\n<!-- 2&#45;&gt;12 -->\n<g id=\"edge12\" class=\"edge\">\n<title>2&#45;&gt;12</title>\n<path fill=\"none\" stroke=\"black\" d=\"M562.01,-460.91C570.71,-451.74 580.02,-441.93 588.97,-432.49\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"591.71,-434.68 596.06,-425.02 586.64,-429.87 591.71,-434.68\"/>\n</g>\n<!-- 4 -->\n<g id=\"node5\" class=\"node\">\n<title>4</title>\n<path fill=\"#3de684\" stroke=\"black\" d=\"M260.5,-306C260.5,-306 130.5,-306 130.5,-306 124.5,-306 118.5,-300 118.5,-294 118.5,-294 118.5,-235 118.5,-235 118.5,-229 124.5,-223 130.5,-223 130.5,-223 260.5,-223 260.5,-223 266.5,-223 272.5,-229 272.5,-235 272.5,-235 272.5,-294 272.5,-294 272.5,-300 266.5,-306 260.5,-306\"/>\n<text text-anchor=\"start\" x=\"126.5\" y=\"-290.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">petal width (cm) ≤ 1.65</text>\n<text text-anchor=\"start\" x=\"160\" y=\"-275.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.041</text>\n<text text-anchor=\"start\" x=\"154.5\" y=\"-260.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 48</text>\n<text text-anchor=\"start\" x=\"145\" y=\"-245.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 47, 1]</text>\n<text text-anchor=\"start\" x=\"143\" y=\"-230.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = versicolor</text>\n</g>\n<!-- 3&#45;&gt;4 -->\n<g id=\"edge4\" class=\"edge\">\n<title>3&#45;&gt;4</title>\n<path fill=\"none\" stroke=\"black\" d=\"M337.21,-341.91C318.61,-331.88 298.57,-321.07 279.59,-310.84\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"281.12,-307.69 270.65,-306.02 277.8,-313.85 281.12,-307.69\"/>\n</g>\n<!-- 7 -->\n<g id=\"node8\" class=\"node\">\n<title>7</title>\n<path fill=\"#c09cf2\" stroke=\"black\" d=\"M477.5,-306C477.5,-306 347.5,-306 347.5,-306 341.5,-306 335.5,-300 335.5,-294 335.5,-294 335.5,-235 335.5,-235 335.5,-229 341.5,-223 347.5,-223 347.5,-223 477.5,-223 477.5,-223 483.5,-223 489.5,-229 489.5,-235 489.5,-235 489.5,-294 489.5,-294 489.5,-300 483.5,-306 477.5,-306\"/>\n<text text-anchor=\"start\" x=\"343.5\" y=\"-290.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">petal width (cm) ≤ 1.55</text>\n<text text-anchor=\"start\" x=\"377\" y=\"-275.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.444</text>\n<text text-anchor=\"start\" x=\"375\" y=\"-260.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 6</text>\n<text text-anchor=\"start\" x=\"365.5\" y=\"-245.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 2, 4]</text>\n<text text-anchor=\"start\" x=\"364\" y=\"-230.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = virginica</text>\n</g>\n<!-- 3&#45;&gt;7 -->\n<g id=\"edge7\" class=\"edge\">\n<title>3&#45;&gt;7</title>\n<path fill=\"none\" stroke=\"black\" d=\"M412.5,-341.91C412.5,-333.65 412.5,-324.86 412.5,-316.3\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"416,-316.02 412.5,-306.02 409,-316.02 416,-316.02\"/>\n</g>\n<!-- 5 -->\n<g id=\"node6\" class=\"node\">\n<title>5</title>\n<path fill=\"#39e581\" stroke=\"black\" d=\"M109,-179.5C109,-179.5 12,-179.5 12,-179.5 6,-179.5 0,-173.5 0,-167.5 0,-167.5 0,-123.5 0,-123.5 0,-117.5 6,-111.5 12,-111.5 12,-111.5 109,-111.5 109,-111.5 115,-111.5 121,-117.5 121,-123.5 121,-123.5 121,-167.5 121,-167.5 121,-173.5 115,-179.5 109,-179.5\"/>\n<text text-anchor=\"start\" x=\"32.5\" y=\"-164.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"19.5\" y=\"-149.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 47</text>\n<text text-anchor=\"start\" x=\"10\" y=\"-134.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 47, 0]</text>\n<text text-anchor=\"start\" x=\"8\" y=\"-119.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = versicolor</text>\n</g>\n<!-- 4&#45;&gt;5 -->\n<g id=\"edge5\" class=\"edge\">\n<title>4&#45;&gt;5</title>\n<path fill=\"none\" stroke=\"black\" d=\"M148.66,-222.91C135.04,-211.1 120.17,-198.22 106.6,-186.45\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"108.62,-183.57 98.77,-179.67 104.03,-188.86 108.62,-183.57\"/>\n</g>\n<!-- 6 -->\n<g id=\"node7\" class=\"node\">\n<title>6</title>\n<path fill=\"#8139e5\" stroke=\"black\" d=\"M240,-179.5C240,-179.5 151,-179.5 151,-179.5 145,-179.5 139,-173.5 139,-167.5 139,-167.5 139,-123.5 139,-123.5 139,-117.5 145,-111.5 151,-111.5 151,-111.5 240,-111.5 240,-111.5 246,-111.5 252,-117.5 252,-123.5 252,-123.5 252,-167.5 252,-167.5 252,-173.5 246,-179.5 240,-179.5\"/>\n<text text-anchor=\"start\" x=\"167.5\" y=\"-164.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"158\" y=\"-149.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"start\" x=\"148.5\" y=\"-134.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 0, 1]</text>\n<text text-anchor=\"start\" x=\"147\" y=\"-119.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = virginica</text>\n</g>\n<!-- 4&#45;&gt;6 -->\n<g id=\"edge6\" class=\"edge\">\n<title>4&#45;&gt;6</title>\n<path fill=\"none\" stroke=\"black\" d=\"M195.5,-222.91C195.5,-212.2 195.5,-200.62 195.5,-189.78\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"199,-189.67 195.5,-179.67 192,-189.67 199,-189.67\"/>\n</g>\n<!-- 8 -->\n<g id=\"node9\" class=\"node\">\n<title>8</title>\n<path fill=\"#8139e5\" stroke=\"black\" d=\"M371,-179.5C371,-179.5 282,-179.5 282,-179.5 276,-179.5 270,-173.5 270,-167.5 270,-167.5 270,-123.5 270,-123.5 270,-117.5 276,-111.5 282,-111.5 282,-111.5 371,-111.5 371,-111.5 377,-111.5 383,-117.5 383,-123.5 383,-123.5 383,-167.5 383,-167.5 383,-173.5 377,-179.5 371,-179.5\"/>\n<text text-anchor=\"start\" x=\"298.5\" y=\"-164.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"289\" y=\"-149.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 3</text>\n<text text-anchor=\"start\" x=\"279.5\" y=\"-134.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 0, 3]</text>\n<text text-anchor=\"start\" x=\"278\" y=\"-119.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = virginica</text>\n</g>\n<!-- 7&#45;&gt;8 -->\n<g id=\"edge8\" class=\"edge\">\n<title>7&#45;&gt;8</title>\n<path fill=\"none\" stroke=\"black\" d=\"M382.66,-222.91C374.31,-211.54 365.22,-199.18 356.84,-187.77\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"359.62,-185.65 350.88,-179.67 353.98,-189.8 359.62,-185.65\"/>\n</g>\n<!-- 9 -->\n<g id=\"node10\" class=\"node\">\n<title>9</title>\n<path fill=\"#9cf2c0\" stroke=\"black\" d=\"M548,-187C548,-187 413,-187 413,-187 407,-187 401,-181 401,-175 401,-175 401,-116 401,-116 401,-110 407,-104 413,-104 413,-104 548,-104 548,-104 554,-104 560,-110 560,-116 560,-116 560,-175 560,-175 560,-181 554,-187 548,-187\"/>\n<text text-anchor=\"start\" x=\"409\" y=\"-171.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">petal length (cm) ≤ 5.45</text>\n<text text-anchor=\"start\" x=\"445\" y=\"-156.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.444</text>\n<text text-anchor=\"start\" x=\"443\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 3</text>\n<text text-anchor=\"start\" x=\"433.5\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 2, 1]</text>\n<text text-anchor=\"start\" x=\"428\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = versicolor</text>\n</g>\n<!-- 7&#45;&gt;9 -->\n<g id=\"edge9\" class=\"edge\">\n<title>7&#45;&gt;9</title>\n<path fill=\"none\" stroke=\"black\" d=\"M436.09,-222.91C441.16,-214.2 446.56,-204.9 451.79,-195.89\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"454.95,-197.43 456.95,-187.02 448.9,-193.91 454.95,-197.43\"/>\n</g>\n<!-- 10 -->\n<g id=\"node11\" class=\"node\">\n<title>10</title>\n<path fill=\"#39e581\" stroke=\"black\" d=\"M461,-68C461,-68 364,-68 364,-68 358,-68 352,-62 352,-56 352,-56 352,-12 352,-12 352,-6 358,0 364,0 364,0 461,0 461,0 467,0 473,-6 473,-12 473,-12 473,-56 473,-56 473,-62 467,-68 461,-68\"/>\n<text text-anchor=\"start\" x=\"384.5\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"375\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 2</text>\n<text text-anchor=\"start\" x=\"365.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 2, 0]</text>\n<text text-anchor=\"start\" x=\"360\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = versicolor</text>\n</g>\n<!-- 9&#45;&gt;10 -->\n<g id=\"edge10\" class=\"edge\">\n<title>9&#45;&gt;10</title>\n<path fill=\"none\" stroke=\"black\" d=\"M455.18,-103.73C449.74,-94.97 443.99,-85.7 438.52,-76.91\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"441.43,-74.95 433.18,-68.3 435.48,-78.64 441.43,-74.95\"/>\n</g>\n<!-- 11 -->\n<g id=\"node12\" class=\"node\">\n<title>11</title>\n<path fill=\"#8139e5\" stroke=\"black\" d=\"M592,-68C592,-68 503,-68 503,-68 497,-68 491,-62 491,-56 491,-56 491,-12 491,-12 491,-6 497,0 503,0 503,0 592,0 592,0 598,0 604,-6 604,-12 604,-12 604,-56 604,-56 604,-62 598,-68 592,-68\"/>\n<text text-anchor=\"start\" x=\"519.5\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"510\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"start\" x=\"500.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 0, 1]</text>\n<text text-anchor=\"start\" x=\"499\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = virginica</text>\n</g>\n<!-- 9&#45;&gt;11 -->\n<g id=\"edge11\" class=\"edge\">\n<title>9&#45;&gt;11</title>\n<path fill=\"none\" stroke=\"black\" d=\"M505.45,-103.73C510.81,-94.97 516.48,-85.7 521.86,-76.91\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"524.89,-78.66 527.12,-68.3 518.92,-75 524.89,-78.66\"/>\n</g>\n<!-- 13 -->\n<g id=\"node14\" class=\"node\">\n<title>13</title>\n<path fill=\"#c09cf2\" stroke=\"black\" d=\"M697,-306C697,-306 572,-306 572,-306 566,-306 560,-300 560,-294 560,-294 560,-235 560,-235 560,-229 566,-223 572,-223 572,-223 697,-223 697,-223 703,-223 709,-229 709,-235 709,-235 709,-294 709,-294 709,-300 703,-306 697,-306\"/>\n<text text-anchor=\"start\" x=\"568\" y=\"-290.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">sepal width (cm) ≤ 3.1</text>\n<text text-anchor=\"start\" x=\"599\" y=\"-275.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.444</text>\n<text text-anchor=\"start\" x=\"597\" y=\"-260.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 3</text>\n<text text-anchor=\"start\" x=\"587.5\" y=\"-245.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 1, 2]</text>\n<text text-anchor=\"start\" x=\"586\" y=\"-230.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = virginica</text>\n</g>\n<!-- 12&#45;&gt;13 -->\n<g id=\"edge13\" class=\"edge\">\n<title>12&#45;&gt;13</title>\n<path fill=\"none\" stroke=\"black\" d=\"M634.5,-341.91C634.5,-333.65 634.5,-324.86 634.5,-316.3\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"638,-316.02 634.5,-306.02 631,-316.02 638,-316.02\"/>\n</g>\n<!-- 16 -->\n<g id=\"node17\" class=\"node\">\n<title>16</title>\n<path fill=\"#8139e5\" stroke=\"black\" d=\"M832,-298.5C832,-298.5 739,-298.5 739,-298.5 733,-298.5 727,-292.5 727,-286.5 727,-286.5 727,-242.5 727,-242.5 727,-236.5 733,-230.5 739,-230.5 739,-230.5 832,-230.5 832,-230.5 838,-230.5 844,-236.5 844,-242.5 844,-242.5 844,-286.5 844,-286.5 844,-292.5 838,-298.5 832,-298.5\"/>\n<text text-anchor=\"start\" x=\"757.5\" y=\"-283.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"744.5\" y=\"-268.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 43</text>\n<text text-anchor=\"start\" x=\"735\" y=\"-253.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 0, 43]</text>\n<text text-anchor=\"start\" x=\"737\" y=\"-238.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = virginica</text>\n</g>\n<!-- 12&#45;&gt;16 -->\n<g id=\"edge16\" class=\"edge\">\n<title>12&#45;&gt;16</title>\n<path fill=\"none\" stroke=\"black\" d=\"M686.89,-341.91C702.27,-329.99 719.07,-316.98 734.37,-305.12\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"736.93,-307.56 742.69,-298.67 732.65,-302.03 736.93,-307.56\"/>\n</g>\n<!-- 14 -->\n<g id=\"node15\" class=\"node\">\n<title>14</title>\n<path fill=\"#8139e5\" stroke=\"black\" d=\"M679,-179.5C679,-179.5 590,-179.5 590,-179.5 584,-179.5 578,-173.5 578,-167.5 578,-167.5 578,-123.5 578,-123.5 578,-117.5 584,-111.5 590,-111.5 590,-111.5 679,-111.5 679,-111.5 685,-111.5 691,-117.5 691,-123.5 691,-123.5 691,-167.5 691,-167.5 691,-173.5 685,-179.5 679,-179.5\"/>\n<text text-anchor=\"start\" x=\"606.5\" y=\"-164.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"597\" y=\"-149.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 2</text>\n<text text-anchor=\"start\" x=\"587.5\" y=\"-134.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 0, 2]</text>\n<text text-anchor=\"start\" x=\"586\" y=\"-119.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = virginica</text>\n</g>\n<!-- 13&#45;&gt;14 -->\n<g id=\"edge14\" class=\"edge\">\n<title>13&#45;&gt;14</title>\n<path fill=\"none\" stroke=\"black\" d=\"M634.5,-222.91C634.5,-212.2 634.5,-200.62 634.5,-189.78\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"638,-189.67 634.5,-179.67 631,-189.67 638,-189.67\"/>\n</g>\n<!-- 15 -->\n<g id=\"node16\" class=\"node\">\n<title>15</title>\n<path fill=\"#39e581\" stroke=\"black\" d=\"M818,-179.5C818,-179.5 721,-179.5 721,-179.5 715,-179.5 709,-173.5 709,-167.5 709,-167.5 709,-123.5 709,-123.5 709,-117.5 715,-111.5 721,-111.5 721,-111.5 818,-111.5 818,-111.5 824,-111.5 830,-117.5 830,-123.5 830,-123.5 830,-167.5 830,-167.5 830,-173.5 824,-179.5 818,-179.5\"/>\n<text text-anchor=\"start\" x=\"741.5\" y=\"-164.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"732\" y=\"-149.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"start\" x=\"722.5\" y=\"-134.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 1, 0]</text>\n<text text-anchor=\"start\" x=\"717\" y=\"-119.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = versicolor</text>\n</g>\n<!-- 13&#45;&gt;15 -->\n<g id=\"edge15\" class=\"edge\">\n<title>13&#45;&gt;15</title>\n<path fill=\"none\" stroke=\"black\" d=\"M681.34,-222.91C694.96,-211.1 709.83,-198.22 723.4,-186.45\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"725.97,-188.86 731.23,-179.67 721.38,-183.57 725.97,-188.86\"/>\n</g>\n</g>\n</svg>\n","text/plain":["<graphviz.sources.Source at 0x7efd4b425900>"]},"metadata":{},"execution_count":49}]},{"cell_type":"markdown","source":["En este ejemplo, utilizamos el conjunto de datos Iris y creamos una instancia del clasificador de árbol de decisión. Luego, utilizamos export_graphviz para generar una representación en formato DOT del árbol. export_graphviz toma varios parámetros, como los nombres de las características y las clases, para mejorar la legibilidad del árbol generado.\n","\n","Después, utilizamos graphviz.Source para crear un objeto de tipo Source que representa el árbol. Luego, llamamos al método render para guardar el árbol en formato PDF con el nombre \"arbol_decision\". También pueden omitir el render si solo quieren mostrar el árbol en el notebook.\n","\n","Recuerden que este código generará un archivo PDF con el árbol de decisión o mostrará el árbol directamente en el notebook, dependiendo de la opción que elijan. Asegúrense de tener instalada la biblioteca graphviz y sus dependencias para que esto funcione correctamente."],"metadata":{"id":"WF18f6094npY"}},{"cell_type":"markdown","source":["##**Ejercicios para el Laboratorio**\n","\n","Para este laboratorio deberán buscar un dataset que cumpla con alguna de las condiciones definidas en la sección de datasets adecuados para el algoritmo. \n","1. Primero importen todas las bibliotecas que vayan a usar para su laboratorio:"],"metadata":{"id":"BVLAVeiE56-D"}},{"cell_type":"code","source":["from sklearn.tree import DecisionTreeClassifier\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score\n","from sklearn.datasets import load_iris\n","import pandas as pd\n","from sklearn.datasets import load_iris\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.tree import export_graphviz\n","from sklearn.datasets import load_iris\n","from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n","import graphviz"],"metadata":{"id":"-yEERo_66jQ3","executionInfo":{"status":"ok","timestamp":1685788232135,"user_tz":360,"elapsed":7,"user":{"displayName":"Totis","userId":"06866148035047094242"}}},"execution_count":50,"outputs":[]},{"cell_type":"markdown","source":["2. Luego cargan el dataset para el trabajo del algoritmo e imprimen parte del dataset a usar."],"metadata":{"id":"gaPJ6rFO7A4B"}},{"cell_type":"code","source":["# \n","\"\"\"\n","Dataset seleccionado: https://www.kaggle.com/datasets/pablomgomez21/drugs-a-b-c-x-y-for-decision-trees\n","\n","Trata de un estudio médico en el que se recopilaron datos de pacientes que tenían una \n","enfermedad en común. Se analizaron diferentes características de los pacientes, \n","como la edad, el sexo, la presión arterial y el colesterol, y se registró el \n","medicamento al que cada paciente respondió durante su tratamiento.\n","\n","El objetivo es utilizar estos datos para construir un modelo que pueda predecir \n","qué medicamento podría ser apropiado para futuros pacientes con la misma enfermedad.\n","\"\"\"\n","\n","dataset = pd.read_csv(\"https://raw.githubusercontent.com/DanielEscobar19/LaboratoriosBigData/main/Laboratorio5/drug200.csv\")\n","print(dataset.head())\n"," "],"metadata":{"id":"UDh9g69s7BMH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1685788232339,"user_tz":360,"elapsed":210,"user":{"displayName":"Totis","userId":"06866148035047094242"}},"outputId":"97464e0b-6f57-423a-d146-a86dd4a0acd9"},"execution_count":51,"outputs":[{"output_type":"stream","name":"stdout","text":["   Age Sex      BP Cholesterol  Na_to_K   Drug\n","0   23   F    HIGH        HIGH   25.355  drugY\n","1   47   M     LOW        HIGH   13.093  drugC\n","2   47   M     LOW        HIGH   10.114  drugC\n","3   28   F  NORMAL        HIGH    7.798  drugX\n","4   61   F     LOW        HIGH   18.043  drugY\n"]}]},{"cell_type":"markdown","source":["3. Separen el dataset en un conjunto de entrenamiento y otro para pruebas:"],"metadata":{"id":"_pxEziPo6n0s"}},{"cell_type":"code","source":["# utiliza la clase LabelEncoder de la biblioteca scikit-learn para convertir variables categóricas en un conjunto de datos en etiquetas numéricas.\n","encoder = LabelEncoder()\n","dataset[\"BP\"] = encoder.fit_transform(dataset[\"BP\"])\n","dataset[\"Sex\"] = encoder.fit_transform(dataset[\"Sex\"])\n","dataset[\"Cholesterol\"] = encoder.fit_transform(dataset[\"Cholesterol\"])\n","\n","# Separar el atributo objetivo (target) y los atributos de características (data)\n","features = dataset.drop([\"Drug\"], axis = 1) # características\n","target = dataset[\"Drug\"]  # atributo objetivo\n","\n","# separa los datos en datos de entrenamiento y pruebas. 20% de los datos serán pruebas y 80% para entrenamiento con una semilla (42)\n","features_train, features_test, target_train, target_test = train_test_split(features, target, test_size=0.2, random_state=42)"],"metadata":{"id":"T5Pu29O_6tks","executionInfo":{"status":"ok","timestamp":1685788232339,"user_tz":360,"elapsed":5,"user":{"displayName":"Totis","userId":"06866148035047094242"}}},"execution_count":52,"outputs":[]},{"cell_type":"markdown","source":["4. Cree el árbol de decisión y entrene el clasificador:"],"metadata":{"id":"Yz5AHkI56vDk"}},{"cell_type":"code","source":["clf = DecisionTreeClassifier()\n","\n","# Entrenar el modelo\n","clf.fit(features_train, target_train)"],"metadata":{"id":"PhSY6VeE7ZR-","colab":{"base_uri":"https://localhost:8080/","height":75},"executionInfo":{"status":"ok","timestamp":1685788232339,"user_tz":360,"elapsed":4,"user":{"displayName":"Totis","userId":"06866148035047094242"}},"outputId":"64597f52-1480-456b-8a79-d4024fe2eb37"},"execution_count":53,"outputs":[{"output_type":"execute_result","data":{"text/plain":["DecisionTreeClassifier()"],"text/html":["<style>#sk-container-id-7 {color: black;background-color: white;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" checked><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div></div></div>"]},"metadata":{},"execution_count":53}]},{"cell_type":"markdown","source":["5. Pase los casos de prueba que definió e imprima la precisión que logró obtener con su clasificador:"],"metadata":{"id":"n-5xXqx37tqj"}},{"cell_type":"code","source":["# Realizar predicciones en los datos de prueba\n","target_pred = clf.predict(features_test)\n","print(target_pred)\n","\n","accuracy = accuracy_score(target_test, target_pred)\n","print(\"Precisión del modelo:\", accuracy)"],"metadata":{"id":"nhuJ27I77uRt","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1685788232339,"user_tz":360,"elapsed":4,"user":{"displayName":"Totis","userId":"06866148035047094242"}},"outputId":"e5b2e997-7f73-40b8-e674-d072dcab5828"},"execution_count":54,"outputs":[{"output_type":"stream","name":"stdout","text":["['drugX' 'drugY' 'drugX' 'drugC' 'drugY' 'drugY' 'drugY' 'drugX' 'drugA'\n"," 'drugX' 'drugA' 'drugX' 'drugY' 'drugA' 'drugB' 'drugY' 'drugB' 'drugX'\n"," 'drugC' 'drugY' 'drugB' 'drugX' 'drugX' 'drugY' 'drugY' 'drugY' 'drugC'\n"," 'drugX' 'drugY' 'drugX' 'drugY' 'drugC' 'drugC' 'drugY' 'drugA' 'drugY'\n"," 'drugX' 'drugA' 'drugY' 'drugA']\n","Precisión del modelo: 1.0\n"]}]},{"cell_type":"markdown","source":["6. Cree varios casos de prueba e imprima varias predicciones utilizando el clasificador entrenado que creo anteriormente:"],"metadata":{"id":"17fW0Rqn7eP9"}},{"cell_type":"code","source":["target_names = dataset[\"Drug\"].unique()  # todas las etiquetas únicas. \n","\n","# creamos nuevos casos de prueba. 50% del dataset como datos de prueba\n","features_train, features_test, target_train, target_test = train_test_split(features, target, test_size=0.5, random_state=42)\n","\n","# Realizamos predicciones con el clasificador ya entrenado y los nuevos casos de prueba\n","target_pred = clf.predict(features_test)\n","# Calcular la precisión del modelo\n","accuracy = accuracy_score(target_test, target_pred)\n","print(\"Precisión del modelo con 50% del dataset como datos de prueba: \", accuracy , \"\\n\")\n","\n","# Imprimir el reporte de clasificación\n","print(classification_report(target_test, target_pred, target_names=target_names) , \"\\n\")\n","\n","#------------------------------------------------------------------------------\n","\n","# creamos nuevos casos de prueba. 70% del dataset como datos de prueba\n","features_train, features_test, target_train, target_test = train_test_split(features, target, test_size=0.7, random_state=9)\n","\n","# Realizamos predicciones con el clasificador ya entrenado y los nuevos casos de prueba\n","target_pred = clf.predict(features_test)\n","# Calcular la precisión del modelo\n","accuracy = accuracy_score(target_test, target_pred)\n","print(\"Precisión del modelo con 70% del dataset como datos de prueba: \", accuracy , \"\\n\")\n","\n","# Imprimir el reporte de clasificación\n","print(classification_report(target_test, target_pred, target_names=target_names) , \"\\n\")\n","\n","#------------------------------------------------------------------------------\n","\n","# creamos nuevos casos de prueba. 90% del dataset como datos de prueba\n","features_train, features_test, target_train, target_test = train_test_split(features, target, test_size=0.9, random_state=58)\n","\n","# Realizamos predicciones con el clasificador ya entrenado y los nuevos casos de prueba\n","target_pred = clf.predict(features_test)\n","# Calcular la precisión del modelo\n","accuracy = accuracy_score(target_test, target_pred)\n","print(\"Precisión del modelo con 90% del dataset como datos de prueba: \", accuracy , \"\\n\")\n","\n","# Imprimir el reporte de clasificación\n","print(classification_report(target_test, target_pred, target_names=target_names) , \"\\n\")"],"metadata":{"id":"pWXx6QLk7mdM","executionInfo":{"status":"ok","timestamp":1685788232532,"user_tz":360,"elapsed":195,"user":{"displayName":"Totis","userId":"06866148035047094242"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"1a16451b-cf2e-4a6f-f135-79a30a3eff79"},"execution_count":55,"outputs":[{"output_type":"stream","name":"stdout","text":["Precisión del modelo con 50% del dataset como datos de prueba:  1.0 \n","\n","              precision    recall  f1-score   support\n","\n","       drugY       1.00      1.00      1.00        16\n","       drugC       1.00      1.00      1.00         8\n","       drugX       1.00      1.00      1.00         7\n","       drugA       1.00      1.00      1.00        27\n","       drugB       1.00      1.00      1.00        42\n","\n","    accuracy                           1.00       100\n","   macro avg       1.00      1.00      1.00       100\n","weighted avg       1.00      1.00      1.00       100\n"," \n","\n","Precisión del modelo con 70% del dataset como datos de prueba:  1.0 \n","\n","              precision    recall  f1-score   support\n","\n","       drugY       1.00      1.00      1.00        15\n","       drugC       1.00      1.00      1.00        12\n","       drugX       1.00      1.00      1.00        13\n","       drugA       1.00      1.00      1.00        42\n","       drugB       1.00      1.00      1.00        58\n","\n","    accuracy                           1.00       140\n","   macro avg       1.00      1.00      1.00       140\n","weighted avg       1.00      1.00      1.00       140\n"," \n","\n","Precisión del modelo con 90% del dataset como datos de prueba:  1.0 \n","\n","              precision    recall  f1-score   support\n","\n","       drugY       1.00      1.00      1.00        22\n","       drugC       1.00      1.00      1.00        14\n","       drugX       1.00      1.00      1.00        15\n","       drugA       1.00      1.00      1.00        46\n","       drugB       1.00      1.00      1.00        83\n","\n","    accuracy                           1.00       180\n","   macro avg       1.00      1.00      1.00       180\n","weighted avg       1.00      1.00      1.00       180\n"," \n","\n"]}]},{"cell_type":"markdown","source":["7. En esta sección, explique lo aprendido con las predicciones hechas:\n","\n","\n","Hemos realizado 4 pruebas con diferentes tamaños de datos de prueba y hasta hemos variado la semilla, y la conclusión es que el modelo está funcionando muy bien. Todas las predicciones son muy precisas, casi perfectas con valores cercanos a 1. El recall (mide cuántos de los casos que realmente pertenecen a una clase determinada el modelo logra identificar de manera correcta) y el f1-score (combina la precisión y el recall, para decir qué tan exactas son las predicciones positivas y qué tan bien se recuperan los casos positivos) también son métricas clave que nos indican que el modelo tiene un gran nivel de recuperación y un equilibrio genial.\n","\n","A nivel conceptual, el modelo es capaz de identificar correctamente diferentes clases de medicamentos, esto sugiere que se han capturado patrones y características importantes en los datos de entrenamiento que permiten hacer predicciones acertadas en los conjuntos de prueba."],"metadata":{"id":"HHcpKJ3y7mto"}},{"cell_type":"markdown","source":["8. Genere una representación gráfica del árbol de decisión obtenido utilizando lo aprendido en puntos anteriores:"],"metadata":{"id":"HqZ3imeJ8A-_"}},{"cell_type":"code","source":["from sklearn.tree import DecisionTreeClassifier\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score\n","from sklearn.datasets import load_iris\n","import pandas as pd\n","from sklearn.datasets import load_iris\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.tree import export_graphviz\n","from sklearn.datasets import load_iris\n","from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n","import graphviz\n","\n","# dataset seleccionado: https://www.kaggle.com/datasets/pablomgomez21/drugs-a-b-c-x-y-for-decision-trees.\n","dataset = pd.read_csv(\"https://raw.githubusercontent.com/DanielEscobar19/LaboratoriosBigData/main/Laboratorio5/drug200.csv\")\n","print(dataset.head())\n","\n","encoder = LabelEncoder()\n","dataset[\"BP\"] = encoder.fit_transform(dataset[\"BP\"])\n","dataset[\"Sex\"] = encoder.fit_transform(dataset[\"Sex\"])\n","dataset[\"Cholesterol\"] = encoder.fit_transform(dataset[\"Cholesterol\"])\n","\n","# Separar el atributo objetivo (target) y los atributos de características (data)\n","features = dataset.drop([\"Drug\"], axis = 1) # características\n","target = dataset[\"Drug\"]  # atributo objetivo\n","\n","features_train, features_test, target_train, target_test = train_test_split(features, target, test_size=0.2, random_state=42)\n","\n","clf = DecisionTreeClassifier()\n","\n","# Entrenar el modelo\n","clf.fit(features_train, target_train)\n","\n","# Realizar predicciones en los datos de prueba\n","target_pred = clf.predict(features_test)\n","print(target_pred)\n","\n","accuracy = accuracy_score(target_test, target_pred)\n","print(\"Precisión del modelo:\", accuracy)\n","features_names = [\"Age\",\"Sex\",\"BP\",\"Cholesterol\",\"Na_to_K\"]\n","target_names = target.unique()\n","\n","dot_data = export_graphviz(clf, out_file=None,\n","                           feature_names=features_names,\n","                           class_names=target_names,\n","                           filled=True, rounded=True,\n","                           special_characters=True)\n","\n","graph = graphviz.Source(dot_data)\n","# graph.render(\"arbol_decision\")  # Guarda el árbol en un archivo en formato PDF\n","\n","# También puedes mostrar el árbol directamente en el notebook\n","graph\n"],"metadata":{"id":"FU6iiDsv8Nt7","colab":{"base_uri":"https://localhost:8080/","height":966},"executionInfo":{"status":"ok","timestamp":1685788232533,"user_tz":360,"elapsed":5,"user":{"displayName":"Totis","userId":"06866148035047094242"}},"outputId":"5c1f1afa-05be-401f-8b4d-ca587896db54"},"execution_count":56,"outputs":[{"output_type":"stream","name":"stdout","text":["   Age Sex      BP Cholesterol  Na_to_K   Drug\n","0   23   F    HIGH        HIGH   25.355  drugY\n","1   47   M     LOW        HIGH   13.093  drugC\n","2   47   M     LOW        HIGH   10.114  drugC\n","3   28   F  NORMAL        HIGH    7.798  drugX\n","4   61   F     LOW        HIGH   18.043  drugY\n","['drugX' 'drugY' 'drugX' 'drugC' 'drugY' 'drugY' 'drugY' 'drugX' 'drugA'\n"," 'drugX' 'drugA' 'drugX' 'drugY' 'drugA' 'drugB' 'drugY' 'drugB' 'drugX'\n"," 'drugC' 'drugY' 'drugB' 'drugX' 'drugX' 'drugY' 'drugY' 'drugY' 'drugC'\n"," 'drugX' 'drugY' 'drugX' 'drugY' 'drugC' 'drugC' 'drugY' 'drugA' 'drugY'\n"," 'drugX' 'drugA' 'drugY' 'drugA']\n","Precisión del modelo: 1.0\n"]},{"output_type":"execute_result","data":{"image/svg+xml":"<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.43.0 (0)\n -->\n<!-- Title: Tree Pages: 1 -->\n<svg width=\"660pt\" height=\"552pt\"\n viewBox=\"0.00 0.00 660.00 552.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 548)\">\n<title>Tree</title>\n<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-548 656,-548 656,4 -4,4\"/>\n<!-- 0 -->\n<g id=\"node1\" class=\"node\">\n<title>0</title>\n<path fill=\"#f8c7ed\" stroke=\"black\" d=\"M488,-544C488,-544 335,-544 335,-544 329,-544 323,-538 323,-532 323,-532 323,-473 323,-473 323,-467 329,-461 335,-461 335,-461 488,-461 488,-461 494,-461 500,-467 500,-473 500,-473 500,-532 500,-532 500,-538 494,-544 488,-544\"/>\n<text text-anchor=\"start\" x=\"357\" y=\"-528.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Na_to_K ≤ 14.829</text>\n<text text-anchor=\"start\" x=\"379.5\" y=\"-513.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.68</text>\n<text text-anchor=\"start\" x=\"366.5\" y=\"-498.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 160</text>\n<text text-anchor=\"start\" x=\"331\" y=\"-483.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [17, 13, 11, 43, 76]</text>\n<text text-anchor=\"start\" x=\"370\" y=\"-468.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = drugB</text>\n</g>\n<!-- 1 -->\n<g id=\"node2\" class=\"node\">\n<title>1</title>\n<path fill=\"#b3b2f5\" stroke=\"black\" d=\"M396.5,-425C396.5,-425 250.5,-425 250.5,-425 244.5,-425 238.5,-419 238.5,-413 238.5,-413 238.5,-354 238.5,-354 238.5,-348 244.5,-342 250.5,-342 250.5,-342 396.5,-342 396.5,-342 402.5,-342 408.5,-348 408.5,-354 408.5,-354 408.5,-413 408.5,-413 408.5,-419 402.5,-425 396.5,-425\"/>\n<text text-anchor=\"start\" x=\"297.5\" y=\"-409.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">BP ≤ 0.5</text>\n<text text-anchor=\"start\" x=\"288\" y=\"-394.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.656</text>\n<text text-anchor=\"start\" x=\"282.5\" y=\"-379.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 84</text>\n<text text-anchor=\"start\" x=\"246.5\" y=\"-364.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [17, 13, 11, 43, 0]</text>\n<text text-anchor=\"start\" x=\"282\" y=\"-349.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = drugA</text>\n</g>\n<!-- 0&#45;&gt;1 -->\n<g id=\"edge1\" class=\"edge\">\n<title>0&#45;&gt;1</title>\n<path fill=\"none\" stroke=\"black\" d=\"M380.97,-460.91C374.21,-451.92 366.98,-442.32 360.02,-433.05\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"362.79,-430.91 353.98,-425.02 357.19,-435.12 362.79,-430.91\"/>\n<text text-anchor=\"middle\" x=\"350.48\" y=\"-446.07\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">True</text>\n</g>\n<!-- 10 -->\n<g id=\"node11\" class=\"node\">\n<title>10</title>\n<path fill=\"#e539c0\" stroke=\"black\" d=\"M562,-417.5C562,-417.5 439,-417.5 439,-417.5 433,-417.5 427,-411.5 427,-405.5 427,-405.5 427,-361.5 427,-361.5 427,-355.5 433,-349.5 439,-349.5 439,-349.5 562,-349.5 562,-349.5 568,-349.5 574,-355.5 574,-361.5 574,-361.5 574,-405.5 574,-405.5 574,-411.5 568,-417.5 562,-417.5\"/>\n<text text-anchor=\"start\" x=\"472.5\" y=\"-402.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"459.5\" y=\"-387.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 76</text>\n<text text-anchor=\"start\" x=\"435\" y=\"-372.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 0, 0, 0, 76]</text>\n<text text-anchor=\"start\" x=\"459\" y=\"-357.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = drugB</text>\n</g>\n<!-- 0&#45;&gt;10 -->\n<g id=\"edge10\" class=\"edge\">\n<title>0&#45;&gt;10</title>\n<path fill=\"none\" stroke=\"black\" d=\"M442.38,-460.91C451.02,-449.54 460.43,-437.18 469.1,-425.77\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"472,-427.74 475.27,-417.67 466.43,-423.51 472,-427.74\"/>\n<text text-anchor=\"middle\" x=\"478.64\" y=\"-438.74\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">False</text>\n</g>\n<!-- 2 -->\n<g id=\"node3\" class=\"node\">\n<title>2</title>\n<path fill=\"#f9e1d0\" stroke=\"black\" d=\"M303,-306C303,-306 172,-306 172,-306 166,-306 160,-300 160,-294 160,-294 160,-235 160,-235 160,-229 166,-223 172,-223 172,-223 303,-223 303,-223 309,-223 315,-229 315,-235 315,-235 315,-294 315,-294 315,-300 309,-306 303,-306\"/>\n<text text-anchor=\"start\" x=\"204.5\" y=\"-290.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Age ≤ 50.5</text>\n<text text-anchor=\"start\" x=\"202\" y=\"-275.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.491</text>\n<text text-anchor=\"start\" x=\"196.5\" y=\"-260.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 30</text>\n<text text-anchor=\"start\" x=\"168\" y=\"-245.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [17, 13, 0, 0, 0]</text>\n<text text-anchor=\"start\" x=\"196\" y=\"-230.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = drugY</text>\n</g>\n<!-- 1&#45;&gt;2 -->\n<g id=\"edge2\" class=\"edge\">\n<title>1&#45;&gt;2</title>\n<path fill=\"none\" stroke=\"black\" d=\"M293.66,-341.91C287.13,-333.01 280.14,-323.51 273.39,-314.33\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"276.03,-312.01 267.28,-306.02 270.39,-316.15 276.03,-312.01\"/>\n</g>\n<!-- 5 -->\n<g id=\"node6\" class=\"node\">\n<title>5</title>\n<path fill=\"#6e6cec\" stroke=\"black\" d=\"M476,-306C476,-306 345,-306 345,-306 339,-306 333,-300 333,-294 333,-294 333,-235 333,-235 333,-229 339,-223 345,-223 345,-223 476,-223 476,-223 482,-223 488,-229 488,-235 488,-235 488,-294 488,-294 488,-300 482,-306 476,-306\"/>\n<text text-anchor=\"start\" x=\"384.5\" y=\"-290.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">BP ≤ 1.5</text>\n<text text-anchor=\"start\" x=\"375\" y=\"-275.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.324</text>\n<text text-anchor=\"start\" x=\"369.5\" y=\"-260.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 54</text>\n<text text-anchor=\"start\" x=\"341\" y=\"-245.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 0, 11, 43, 0]</text>\n<text text-anchor=\"start\" x=\"369\" y=\"-230.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = drugA</text>\n</g>\n<!-- 1&#45;&gt;5 -->\n<g id=\"edge5\" class=\"edge\">\n<title>1&#45;&gt;5</title>\n<path fill=\"none\" stroke=\"black\" d=\"M353.68,-341.91C360.36,-332.92 367.51,-323.32 374.4,-314.05\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"377.21,-316.13 380.37,-306.02 371.59,-311.96 377.21,-316.13\"/>\n</g>\n<!-- 3 -->\n<g id=\"node4\" class=\"node\">\n<title>3</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M135,-179.5C135,-179.5 12,-179.5 12,-179.5 6,-179.5 0,-173.5 0,-167.5 0,-167.5 0,-123.5 0,-123.5 0,-117.5 6,-111.5 12,-111.5 12,-111.5 135,-111.5 135,-111.5 141,-111.5 147,-117.5 147,-123.5 147,-123.5 147,-167.5 147,-167.5 147,-173.5 141,-179.5 135,-179.5\"/>\n<text text-anchor=\"start\" x=\"45.5\" y=\"-164.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"32.5\" y=\"-149.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 17</text>\n<text text-anchor=\"start\" x=\"8\" y=\"-134.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [17, 0, 0, 0, 0]</text>\n<text text-anchor=\"start\" x=\"32\" y=\"-119.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = drugY</text>\n</g>\n<!-- 2&#45;&gt;3 -->\n<g id=\"edge3\" class=\"edge\">\n<title>2&#45;&gt;3</title>\n<path fill=\"none\" stroke=\"black\" d=\"M180.6,-222.91C163.74,-210.88 145.32,-197.73 128.57,-185.79\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"130.16,-182.63 119.99,-179.67 126.1,-188.32 130.16,-182.63\"/>\n</g>\n<!-- 4 -->\n<g id=\"node5\" class=\"node\">\n<title>4</title>\n<path fill=\"#7be539\" stroke=\"black\" d=\"M300,-179.5C300,-179.5 177,-179.5 177,-179.5 171,-179.5 165,-173.5 165,-167.5 165,-167.5 165,-123.5 165,-123.5 165,-117.5 171,-111.5 177,-111.5 177,-111.5 300,-111.5 300,-111.5 306,-111.5 312,-117.5 312,-123.5 312,-123.5 312,-167.5 312,-167.5 312,-173.5 306,-179.5 300,-179.5\"/>\n<text text-anchor=\"start\" x=\"210.5\" y=\"-164.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"197.5\" y=\"-149.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 13</text>\n<text text-anchor=\"start\" x=\"173\" y=\"-134.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 13, 0, 0, 0]</text>\n<text text-anchor=\"start\" x=\"196.5\" y=\"-119.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = drugC</text>\n</g>\n<!-- 2&#45;&gt;4 -->\n<g id=\"edge4\" class=\"edge\">\n<title>2&#45;&gt;4</title>\n<path fill=\"none\" stroke=\"black\" d=\"M237.85,-222.91C237.94,-212.2 238.04,-200.62 238.13,-189.78\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"241.63,-189.7 238.22,-179.67 234.63,-189.64 241.63,-189.7\"/>\n</g>\n<!-- 6 -->\n<g id=\"node7\" class=\"node\">\n<title>6</title>\n<path fill=\"#efeffd\" stroke=\"black\" d=\"M475,-187C475,-187 344,-187 344,-187 338,-187 332,-181 332,-175 332,-175 332,-116 332,-116 332,-110 338,-104 344,-104 344,-104 475,-104 475,-104 481,-104 487,-110 487,-116 487,-116 487,-175 487,-175 487,-181 481,-187 475,-187\"/>\n<text text-anchor=\"start\" x=\"358\" y=\"-171.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Cholesterol ≤ 0.5</text>\n<text text-anchor=\"start\" x=\"374\" y=\"-156.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.499</text>\n<text text-anchor=\"start\" x=\"368.5\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 23</text>\n<text text-anchor=\"start\" x=\"340\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 0, 11, 12, 0]</text>\n<text text-anchor=\"start\" x=\"368\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = drugA</text>\n</g>\n<!-- 5&#45;&gt;6 -->\n<g id=\"edge6\" class=\"edge\">\n<title>5&#45;&gt;6</title>\n<path fill=\"none\" stroke=\"black\" d=\"M410.15,-222.91C410.08,-214.65 410.01,-205.86 409.93,-197.3\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"413.43,-196.99 409.85,-187.02 406.43,-197.05 413.43,-196.99\"/>\n</g>\n<!-- 9 -->\n<g id=\"node10\" class=\"node\">\n<title>9</title>\n<path fill=\"#3c39e5\" stroke=\"black\" d=\"M640,-179.5C640,-179.5 517,-179.5 517,-179.5 511,-179.5 505,-173.5 505,-167.5 505,-167.5 505,-123.5 505,-123.5 505,-117.5 511,-111.5 517,-111.5 517,-111.5 640,-111.5 640,-111.5 646,-111.5 652,-117.5 652,-123.5 652,-123.5 652,-167.5 652,-167.5 652,-173.5 646,-179.5 640,-179.5\"/>\n<text text-anchor=\"start\" x=\"550.5\" y=\"-164.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"537.5\" y=\"-149.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 31</text>\n<text text-anchor=\"start\" x=\"513\" y=\"-134.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 0, 0, 31, 0]</text>\n<text text-anchor=\"start\" x=\"537\" y=\"-119.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = drugA</text>\n</g>\n<!-- 5&#45;&gt;9 -->\n<g id=\"edge9\" class=\"edge\">\n<title>5&#45;&gt;9</title>\n<path fill=\"none\" stroke=\"black\" d=\"M468.79,-222.91C486.22,-210.77 505.28,-197.49 522.55,-185.46\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"524.67,-188.25 530.88,-179.67 520.67,-182.51 524.67,-188.25\"/>\n</g>\n<!-- 7 -->\n<g id=\"node8\" class=\"node\">\n<title>7</title>\n<path fill=\"#39e5c5\" stroke=\"black\" d=\"M388,-68C388,-68 265,-68 265,-68 259,-68 253,-62 253,-56 253,-56 253,-12 253,-12 253,-6 259,0 265,0 265,0 388,0 388,0 394,0 400,-6 400,-12 400,-12 400,-56 400,-56 400,-62 394,-68 388,-68\"/>\n<text text-anchor=\"start\" x=\"298.5\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"285.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 11</text>\n<text text-anchor=\"start\" x=\"261\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 0, 11, 0, 0]</text>\n<text text-anchor=\"start\" x=\"285\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = drugX</text>\n</g>\n<!-- 6&#45;&gt;7 -->\n<g id=\"edge7\" class=\"edge\">\n<title>6&#45;&gt;7</title>\n<path fill=\"none\" stroke=\"black\" d=\"M378.59,-103.73C371.82,-94.79 364.64,-85.32 357.85,-76.36\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"360.57,-74.15 351.74,-68.3 354.99,-78.38 360.57,-74.15\"/>\n</g>\n<!-- 8 -->\n<g id=\"node9\" class=\"node\">\n<title>8</title>\n<path fill=\"#3c39e5\" stroke=\"black\" d=\"M553,-68C553,-68 430,-68 430,-68 424,-68 418,-62 418,-56 418,-56 418,-12 418,-12 418,-6 424,0 430,0 430,0 553,0 553,0 559,0 565,-6 565,-12 565,-12 565,-56 565,-56 565,-62 559,-68 553,-68\"/>\n<text text-anchor=\"start\" x=\"463.5\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"450.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 12</text>\n<text text-anchor=\"start\" x=\"426\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 0, 0, 12, 0]</text>\n<text text-anchor=\"start\" x=\"450\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = drugA</text>\n</g>\n<!-- 6&#45;&gt;8 -->\n<g id=\"edge8\" class=\"edge\">\n<title>6&#45;&gt;8</title>\n<path fill=\"none\" stroke=\"black\" d=\"M440.03,-103.73C446.73,-94.79 453.82,-85.32 460.53,-76.36\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"463.37,-78.4 466.56,-68.3 457.77,-74.21 463.37,-78.4\"/>\n</g>\n</g>\n</svg>\n","text/plain":["<graphviz.sources.Source at 0x7efd4b42f8b0>"]},"metadata":{},"execution_count":56}]},{"cell_type":"markdown","source":["9. Concluya el tema explicando lo aprendido en este laboratorio:\n","\n","En el laboratorio aprendimos que un árbol de decisión es es una técnica de aprendizaje automático muy útil y versátil y que se usa cuando queremos tomar decisiones basadas en múltiples características o atributos de un conjunto de datos con características numéricas, de alta dimensionalidad, con relaciones no lineales, que puede trabajar con valores atípicos y características faltantes o que requieran interpretabilidad.\n","\n","En el dataset que utilizamos, teníamos pocas características (edad, el sexo, la presión arterial y el colesterol) y un objetivo (target: medicamento) significativo e importante, por lo que el árbol generado es poco profundo y el modelo resultó muy preciso, logrando identificar patrones que le permitieron hacer predicciones acertadas (a partir de las características, logra identificar el target_name de los medicamentos una precisión superior al 98%). El modelo pudo predecir qué medicamento podría ser apropiado para futuros pacientes con la misma enfermedad.\n","\n","Además descubrimos nuevos atributos importantes que explican qué tan exactas son las predicciones positivas (precisión) y qué tan bien se recuperan los datos positivos (recall), así como el cómo equilibrar estas dos cosas (f1-score). \n","\n","En cuanto a la visualización del árbol de decisión, aprendimos a representarlo gráficamente. Esto nos permitió observar los nodos internos, que representan las características y las decisiones tomadas, así como las raíces, que muestran los resultados o las clasificaciones finales. "],"metadata":{"id":"yRQSUsiy8Ol3"}}]}